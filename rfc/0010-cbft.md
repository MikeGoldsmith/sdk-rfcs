# Meta

 - RFC Name: Couchbase Full Text Search Index Query (FTS)
 - RFC ID: 0010-fulltext
 - Start Date: 2016-03-04
 - Owner: Michael Nitschinger, Simon Basl√©
 - Current Status: Draft

# Summary
This RFC describes the SDK API and behavior exposure of the Couchbase Server Full Text Search (FTS) capabilities, shipping with Couchbase Server 4.5 ("watson"). It describes both the user-facing APIs, as well as the protocol level details which are needed to implement the APIs.

**Table of Contents:**
<!-- TOC depthFrom:1 depthTo:4 withLinks:1 updateOnSave:1 orderedList:0 -->

- [Meta](#meta)
- [Summary](#summary)
- [Motivation](#motivation)
- [General Design](#general-design)
	- [1. Query Type Overview](#1-query-type-overview)
	- [2. High Level API Overview](#2-high-level-api-overview)
	- [3. Request Query Options](#3-request-query-options)
		- [3.1. Search Request Params](#31-search-request-params)
			- [Limit](#limit)
			- [Skip](#skip)
			- [Explain](#explain)
			- [Highlighting](#highlighting)
			- [Fields](#fields)
			- [Facets](#facets)
			- [Server Side Timeout](#server-side-timeout)
			- [Query Consistency](#query-consistency)
		- [3.2. Common Query Options](#32-common-query-options)
			- [Boosting](#boosting)
		- [3.3. Match Query Options](#33-match-query-options)
			- [Match](#match)
			- [Field](#field)
			- [Analyzer](#analyzer)
			- [Prefix Length](#prefix-length)
			- [Fuzziness](#fuzziness)
		- [3.4. Match Phrase Query Options](#34-match-phrase-query-options)
			- [Match Phrase](#match-phrase)
			- [Field](#field)
			- [Analyzer](#analyzer)
		- [3.5. Fuzzy Query Options](#35-fuzzy-query-options)
			- [Term](#term)
			- [Prefix Length](#prefix-length)
			- [Fuzziness](#fuzziness)
			- [Field](#field)
		- [3.6. Prefix Query Options](#36-prefix-query-options)
			- [Prefix](#prefix)
			- [Field](#field)
		- [3.7. Regexp Query Options](#37-regexp-query-options)
			- [Regexp](#regexp)
			- [Field](#field)
		- [3.8. String Query Options](#38-string-query-options)
			- [Match](#match)
		- [3.9. Numeric Range Query Options](#39-numeric-range-query-options)
			- [Min](#min)
			- [Max](#max)
			- [Field](#field)
		- [3.10. Date Range Query Options](#310-date-range-query-options)
			- [Start](#start)
			- [End](#end)
			- [DateTime Parser](#datetime-parser)
			- [Field](#field)
		- [3.11. Compound Queries - Conjunction Query](#311-compound-queries-conjunction-query)
		- [3.12. Compound Queries - Disjunction Query](#312-compound-queries-disjunction-query)
			- [Min](#min)
		- [3.13. Compound Queries - Boolean Query](#313-compound-queries-boolean-query)
	- [4. Search Response](#4-search-response)
		- [4.1. Status and Errors](#41-status-and-errors)
			- [The HTTP 400 case](#the-http-400-case)
			- [Execution Error Handling](#execution-error-handling)
		- [4.2. Hits](#42-hits)
			- [Explanations](#explanations)
			- [Locations](#locations)
			- [Fragments](#fragments)
			- [Fields](#fields)
		- [4.3. Facet Results](#43-facet-results)
			- [Term Facet Results](#term-facet-results)
			- [Numeric Range Facet Results](#numeric-range-facet-results)
			- [Date Range Facet Results](#date-range-facet-results)
- [Language Specifics](#language-specifics)
- [Unresolved Questions](#unresolved-questions)
- [Signoff](#signoff)

<!-- /TOC -->

# Motivation
Couchbase Server 4.5 ships with FTS support and to provide first-class support for our users and customers we need to properly expose it in the SDK APIs.

Note that this RFC does only deal with index querying, not index maintenance and administration.

# General Design
The general design of using FTS is to expose a "fluent API", similar to other newer features like subdoc. The fluent pattern works very well in the FTS case because the user needs to craft the request out of a list of (sometimes complex) options. A properly designed API can guide the user the right way and also prevent invalid query option inputs, by having constructors take the mandatory parameters and have optional parameters introduced through setters that can be chained.

## 1. Query Type Overview

There are different types of queries which can be executed, some of them (compound queries) contain other queries in them. They all provide a common set of options and then each one has a unique option set. The following provides an overview of the supported query types by the server. Each of them will be detailed later in the request building section.

Simple Queries:

 - **Match Query:** A match query analyzes the input text and uses that analyzed text to query the index.
 - **Match Phrase Query:** The input text is analyzed and a phrase query is built with the terms resulting from the analysis.
 - **Fuzzy Query:** A fuzzy query is a term query that matches terms within a specified edit distance (Levenshtein distance).
 - **Prefix Query:** The prefix query finds documents containing terms that start with the provided prefix.
 - **Regexp Query:** Finds documents containing terms that match the specified regular expression.
 - **String Query:** The query string query allows humans to describe complex queries using a simple syntax.

Range Queries:

 - **Date Range Query:** The date range query finds documents containing a date value in the specified field within the specified range.
 - **Numeric Range Query:** The numeric range query finds documents containing a numeric value in the specified field within the specified range.

Compound Queries:

 - **Conjunction Query:** Result documents must satisfy all of the child queries.
 - **Disjunction Query:** Result documents must satisfy a configurable min number of child queries.
 - **Boolean Query:** The boolean query is a useful combination of conjunction and disjunction queries.

## 2. High Level API Overview
This section describes how the overall API looks like (to be expanded).

For both bucket and cluster level, the approach is the same. Right now only Bucket level is defined in this RFC.

```java
bucket.query(SearchQuery[, SearchParams]);
```

All query types described below must implement the `SearchQuery` marker interface or base class (including compound queries since they can be nested too).

Here is an example of a String query with some search params:

```java
bucket.query(new StringQuery("description:awesome").boost(2), new SearchParams().limit(5))
```

If idiomatic by the language, it makes sense to provide static factory methods (or similar helpers) to guide the user in the right direction since there are many different query options available. So for example the `SearchQuery` can contain factory methods in a form like this:

```java
bucket.query(SearchQuery.string("+water +abv:>10"), new SearchParams().limit(5))
```

This removes cognitive load, since the user only needs to remember "SearchQuery" and will have all supported query methods available immediately.

## 3. Request Query Options

### 3.1. Search Request Params
All options described in this section are not bound to a specific search option, but rather treated as a separate param set as an optional argument. They affect the query as a whole, independent of the actual search method (including compound queries) used.

They are part of the `SearchParams` object which can be used optionally by the user.

If not explicitly provided by the user, **the default settings indicated below should be applied by the SDK on every request** (for example to make sure the server timeout is always passed).

`new SearchParams().limit(1).skip(5).explain()`

#### Limit
The `limit` option limits the number of matches returned from the complete result set. The actual HTTP query field is called `size`, but to match it with N1QL and Views it makes sense to name it similarly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `limit(int limit)` | `size` | JSON Number | - | >  0, if not set no size is used (no default value) |

**Examples:** `.limit(10)`

#### Skip
The `skip` option indicates how many matches are skipped on the result set before starting to return the matches. The actual HTTP query field is called `from`, but to match it with N1QL and Views it makes sense to name it similarly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `skip(int skip)` | `from` | JSON Number | - | >  0, if not set no size is used (no default value) |

**Examples:** `.skip(5)`

#### Explain
The boolean `explain` field triggers inclusion of additional search result score explanations.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `explain()` | `explain` | JSON Boolean | - | -|



#### Highlighting
This option allows the user to specify optional highlighting of the result set. It allows to both set the `style` and the `fields` to highlight. Highlighting is disabled by default.


| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `highlight(HighlightStyle style, [String... fields])` | `highlight` | JSON Object `{"style": "foo", "fields": ["fa", "fb"]}` | - | -|

The `HighlightStyle` is an enumeration (or similar with a fixed set of possible values) which describes the highlighters the Server supports. The following options are available:

```java
enum HighlightStyle {
  HTML, // maps to "html" on the wire
  ANSI  // maps to "ansi" on the wire
}
```

The `style` is required, but if no `field` is provided FTS will just highlight all fields where there is a match.

**Examples:** `.highlight(HighlightStyle.HTML)`, `.highlight(HighlightStyle.HTML, "description", "name")`

#### Fields
This option describes a list of field values which should be retrieved for result documents, provided they
were stored while indexing.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `fields(String... fields)` | `fields` | JSON Array (of strings) `...,"fields": ["a", "b"],...` | - | -|

**Examples:** `.fields("description", "name")`


#### Facets
Facets allow to aggregate information collected on a particular result set. Currently there are three different types of facets supported:

 - Term Facet: A term facet categorizes the matching documents into categories given by a particular field. The `size`/`limit` parameter drives how many categories are returned (only the top n categories are returned).
 - Numeric Range Facet: A numeric range facet works by the user defining their own numeric ranges. The facet then counts how many of the matching documents fall into a particular range for the faceted field.
 - Date Range Facet: same as numeric, but on dates instead of numbers.

Note that range boundaries are all inclusive, and ranges can overlap (so a document can fall eg. in two overlapping date ranges).

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `facets()`    | `facets`     | JSON Object of Objects `{name: {facet}, name: {facet}...}` | - | For a single facet, either `numeric_ranges` or `date_ranges` is allowed. If omitted it is a term facet. |

The 3 types of facets have corresponding methods on the `facets()` builder:

| Facet Type | Builder Method | Range Wire Format |
| ---------- | -------------- | ------------ |
| term       | `facets().addTerm(String name, String field, int limit)` | - |
| numeric    | `facets().addNumeric(String name, String field, int limit, NumericRange... ranges)` | `[ { "name": name of range (string), "min": inclusive lower bound (float), "max": inclusive upper bound (float) } ]` |
| date       | `facets().addDate(String name, String field, int limit, DateRange... ranges)` | `[ { "name": name of range (string), "start": "2011-08-30T13:22:53.108Z", "end": "... quoted string rfc 3339" } ]`  |

At a minimum, each `{facet}` has a `field` and a `size`. The size drives the number of facets/categories returned. Numeric facets also have an array `numeric_ranges` of `{numericRange}` objects.
Date faces instead have an array `date_ranges` of `{dateRange}` objects. See following wire examples for term, numeric and date:

```json
"facets": {
    "myTermFacet": {
        "field": "fieldName",
        "size": 3
    }
}
```

`min` and `max` are optional, but at least one of the two should be provided. `name` is technically optional but having several ranges without a name can confuse things, so it is recommended to make it mandatory in the API:

```json
"facets": {
    "myNumericFacet": {
        "field": "fieldName",
        "size": 2,
        "numeric_ranges": [
            { "name":"range1", "min": 0.1, "max": 3.0 },
            { "name":"range2", "min": 3.1 }
        ]
    }
}
```

`start` and `end` are optional, but at least one of the two should be provided. `name` is technically optional in the request but it is recommended to make it mandatory in the API:

```json
"facets": {
    "myDateFacet": {
        "field": "fieldName",
        "size": 2,
        "date_ranges": [
            { "name":"old", "end": "2016-01-01T00:00:00"},
            { "name":"thisYear", "start": "2016-01-01T00:00:01"},
            { "name":"theYear2011", "start": "2011-01-01T00:00:00", "end": "2011-12-31T23:59:59"}
        ]
    }
}
```

**Examples:**

```java
.facets().addTerm("type", "type", 5);

.facets().addNumeric("strength", "abv", 3,
	numeric("strong", 5),
	numeric("middle", 3.1, 4.99),
	numeric("light", 0, 3.0));

.facets().addDate("age", "updated", 2,
	date("old", null, "2016-01-01T00:00:00"),
	date("thisYear", "2016-01-01T00:00:01"),
	date("theYear2011", "2011-01-01T00:00:00", "2011-12-31T23:59:59"));
```

Since multiple facets can be used in one request, subsequent calls to `facets()` are additive (as long as they have different names).

#### Server Side Timeout
The server side timeout allows to specify an upper boundary of request execution so
that it potentially doesn't run infinitely.

The timeout is expressed as a `long`, a number of `milliseconds` on the wire. SDKs where this is  relevant can substitute this with a more idiomatic / rich representation of duration (eg. in .NET a `TimeSpan` instance, in Java a pair of `long` and `TimeUnit`, as long as the representation can be converted to an amount of milliseconds.

Note that like N1QL, the SDK must pass the client side timeout, if not overridden by
the user down automatically, since there is no point in running the request if no one
is listening anymore.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `serverSideTimeout(long timeout)` | `ctl.timeout` | JSON Number (positive and > 0) in milliseconds | client side timeout (75 seconds) | must be greater than 0 |

**Examples:** `.timeout(long timeout)` // or equivalent timeout abstraction whatever is used in the SDK

#### Query Consistency

TODO, note that REQUEST_PLUS is slated for spock ([MB-18428](https://issues.couchbase.com/browse/MB-18428)).This should look like the stuff we have in N1QL, abstracting over the mutation tokens with `consistentWith`.

### 3.2. Common Query Options
The following list of options are available for every type of query below (including compound queries).

#### Boosting
The boost parameter is used to increase the relative weight of a clause (with a boost greater than 1) or decrease the relative weight (with a boost between 0 and 1).

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `boost(double boost)` | `query.boost` | JSON Number | - | `>= 0` |

**Examples:** `.boost(1.5)`, `.boost(0.3)`

### 3.3. Match Query Options
A match query is like a term query, but the input text is analyzed first. An attempt is made to use the same analyzer that was used when the field was indexed.

```java
new MatchQuery("salty beers").analyzer("custom_analyzer").boost(1.0).fuzziness(2)
```

#### Match
The input string to be matched against. The match string is required.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `new MatchQuery(String match)` | `query.match` | JSON String | - | must not be empty |

**Examples:** `new MatchQuery("salty beers")`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

#### Analyzer

Analyzers are used to transform input text into a stream of tokens for indexing. The Server comes with built-in analyzers and the users can create their own. The string here is the name of the analyzer used.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `analyzer(String analyzer)` | `query.analyzer` | JSON String | - | - |

**Examples:** `.analyzer("my_cool_analyzer")`

#### Prefix Length
This parameter can be used to require that the term also have the same prefix of the specified length.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `prefixLength(int length)` | `query.prefix_length` | JSON Number | - | if 0 not used, must never be negative. |

**Examples:** `.prefixLength(5)`

#### Fuzziness
The match query can optionally perform fuzzy matching. If the fuzziness parameter is set to a non-zero integer the analyzed text will be matched with the specified level of fuzziness.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `fuzziness(int fuzziness)` | `query.fuzziness` | JSON Number | - | - |

**Examples:** `.fuzziness(1)`

### 3.4. Match Phrase Query Options
The input text is analyzed and a phrase query is built with the terms resulting from the analysis. This type of query searches for terms occurring in the specified positions and offsets. This depends on term vectors, which are consulted to determine phrase distance.

```java
new MatchPhraseQuery("salty beers").analyzer("custom_analyzer").boost(1.0)
```

#### Match Phrase
The input phrase to be matched against. The match phrase string is required.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `new MatchPhraseQuery(String matchPhrase)` | `query.match_phrase` | JSON String | - | - |

**Examples:** `new MatchPhraseQuery("salty beers")`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

#### Analyzer

Analyzers are used to transform input text into a stream of tokens for indexing. The Server comes with built-in analyzers and the users can create their own. The string here is the name of the analyzer used.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `analyzer(String analyzer)` | `query.analyzer` | JSON String | - | - |

**Examples:** `.analyzer("my_cool_analyzer")`

### 3.5. Fuzzy Query Options
A fuzzy query is a term query that matches terms within a specified edit distance (Levenshtein distance). Also, you can optionally specify that the term must have a matching prefix of the specified length.

Here is an example of a `fuzzy` query:

```java
new FuzzyQuery("my term").fuzziness(3)
```

#### Term
The input term to be matched against. The term string is required.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) String term` | `query.term` | JSON String | - | - |

**Examples:** `new FuzzyQuery("my term")`

#### Prefix Length
The `prefix_length` parameter can be used to require that the term also have the same prefix of the specified length.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `prefixLength(int length)` | `query.prefix_length` | JSON Number | - | if 0 not used, must never be negative. |

**Examples:** `.prefixLength(5)`

#### Fuzziness
The match query can optionally perform fuzzy matching. If the fuzziness parameter is set to a non-zero integer the analyzed text will be matched with the specified level of fuzziness.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `fuzziness(int fuzziness)` | `query.fuzziness` | JSON Number | - (the server picks 2 as the default) | boost must be greater or equal to 0 |

**Examples:** `.fuzziness(1)`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

### 3.6. Prefix Query Options
The prefix query finds documents containing terms that start with the provided prefix.
```java
new PrefixQuery("foo")
```

#### Prefix
The prefix to be analyzed and used against. The prefix string is required.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) String prefix` | `query.prefix` | JSON String | - | - |

**Examples:** `new PrefixQuery("foo")`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

### 3.7. Regexp Query Options
Regexp query finds documents containing terms that match the specified regular expression.

Here is an example of a `regexp` query:

```java
new RegexpQuery("[A-Za-z0-9]")
```

#### Regexp
The regexp to be analyzed and used against. The regexp string is required.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) String regexp` | `query.regexp` | JSON String | - | - |

**Examples:** `new RegexpQuery("[A-Za-z0-9]")`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

### 3.8. String Query Options
The query string query allows humans to describe complex queries using a simple syntax.

```java
new StringQuery("description:water and some other stuff").boost(1)
```

#### Match
The query string to be analyzed and used against. The query string is required.


| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) String query` | `query.query` | JSON String | - | - |

**Examples:** `new StringQuery("description:water and some other stuff")`

### 3.9. Numeric Range Query Options
The numeric range query finds documents containing a numeric value in the specified field within the specified range. Either min or max can be omitted, but not both.

#### Min
The lower end of the range, inclusive by default.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `min(float min[, boolean inclusive])` | `query.min` & `query.inclusive_min` | JSON Number & JSON Boolean | min omitted, inclusive = true | - |

**Examples:** `.min(10, false)`

#### Max
The higher end of the range, exclusive by default.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `max(float max[, boolean inclusive])` | `query.max` & `query.inclusive_max` | JSON Number & JSON Boolean | min omitted, inclusive = false | - |

**Examples:** `.max(500, true)`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

### 3.10. Date Range Query Options
The date range query finds documents containing a date value in the specified field within the specified range. Either start or end can be omitted, but not both.

#### Start
The start date of the range, (inclusive by default ??todo).

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `start(String start[, boolean inclusive])` | `query.start` & `query.inclusive_start` | JSON String & JSON Boolean | start omitted, inclusive = true | - |

**Examples:** `.start("date format supported", false)`

#### End
The end date of the range, (exclusive by default ??todo).

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `end(String end[, boolean inclusive])` | `query.end` & `query.inclusive_end` | JSON String & JSON Boolean | end omitted, inclusive = false | - |

**Examples:** `.end("date format supported", true)`

#### DateTime Parser
This field enables one to specify a custom date time parser.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `dateTimeParser(String name)` | `query.datetime_parser` | JSON String | - | - |

**Examples:** `.dateTimeParser("customParser")`

#### Field
If a field is specified, only terms in that field will be matched. This can also affect the used analyzer if one isn't specified explicitly.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `field(String field)` | `query.field` | JSON String | - | - |

**Examples:** `.field("fieldname")`

### 3.11. Compound Queries - Conjunction Query
The conjunction query is a compound query. The result documents must satisfy all of the child queries. It is possible to recursively nest compound queries.

```java
new ConjunctionQuery(SearchQuery queries....)
```

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) SearchQuery... queries` | `query.conjuncts` | JSON Array | - | - |

**Examples:** `new ConjunctionQuery(new StringQuery(...), new MatchQuery(...))`


### 3.12. Compound Queries - Disjunction Query
The disjunction query is a compound query. The result documents must satisfy a configurable min number of child queries. By default this min is set to 1.

```java
new DisjunctionQuery(SearchQuery queries....)
```

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `(constructor argument) SearchQuery... queries` | `query.disjuncts` | JSON Array | - | - |

**Examples:** `new DisjunctionQuery(new StringQuery(...), new MatchQuery(...))`

#### Min
The minimum number of child queries that must be satisfied for the disjunction query.

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `min(int min)` | `query.min` | JSON Number | - | - |

**Examples:** `.min(2)`


### 3.13. Compound Queries - Boolean Query
The boolean query is a useful combination of conjunction and disjunction queries. A boolean query takes three lists of queries:

 - must - result documents must satisfy all of these queries.
 - should - result documents should satisfy these queries.
 - must not - result documents must not satisfy any of these queries.

```java
new BooleanQuery().must(SearchQuery).should(SearchQuery).mustNot(SearchQuery)
```

| Builder Name | Request Path | Wire Type | Default | Constraints |
| ------------ | ------------ | --------- | ------- | ----------- |
| `must(SearchQuery query)` | `query.must` | JSON Object | - | - |
| `should(SearchQuery query)` | `query.should` | JSON Object | - | - |
| `mustNot(SearchQuery query)` | `query.must_not` | JSON Object | - | - |

## 4. Search Response

As of Watson BETA, two response cases can occur:

 1. **the request is well-formed**: a `HTTP 200` is returned. The `Content-Type` of the response is `application/json` (note the actual header will also contain the API version, eg. `application/json;version=1.0.0`). This response can be returned either when all was successful or when some errors happened **during execution** (see section 4.1).
 2. **the request is malformed**: a `HTTP 400` error is returned. The `Content-Type` is `text/plain; charset=utf-8` and the body of the response contains a dump of the incriminating query, the Go stacktrace of the error and ends in an error message. It **should** be possible to extract a top level error message by extracting the string after the last occurrence of "`, err:`" (last line in body).

The following description of the response format focuses on case 1 above. Like with N1Ql and Views the search response can be separated into the actual returned rows and associated metadata.

```
SearchQueryResult {
  "status": {
    "total": long
    "failed": long
    "successful": long
    "errors": [ string, ... ] //optional
  },
  "request": {JSON object}
  "hits": [ {SearchQueryRow}, ... ]
  "total_hits": long
  "max_score": double
  "took": long
  "facets": {Facets}
}
```

This can be represented by a `SearchQueryResult` interface with at least the following methods:

| Method           | Response Path    | JSON Type         | Example   | SDK Type |
| ---------------- | ---------------- | ----------------- | --------- | -------- |
| `count()`        | `status.total`   | Number            |¬†-         |¬†long |
| `rowCount()`     | `status.success` | Number            |¬†-         |¬†long |
| `errorCount()`   | `status.failed`  | Number            |¬†-         |¬†long |
| `errors()`       | `status.errors`  | Array of Strings  |¬†-         |¬†seq. of `String` |
| `success()`      | -                | -                 |¬†-         |¬†boolean |
| `took()`         | `took`           | Number            | 984127591 | long |
| `totalHits()`    | `total_hits`     | Number            | 6039      | long |
| `maxScore()`     | `max_score`      | Number            | 0.3530367 | double |
| `hits()`         | `hits`           | Array of Objects  | -         | sequence of `SearchQueryRow` |
| `facets()`       | `facets`         | Object of Objects | -         | `Map` or `Facets` |

### 4.1. Status and Errors
FTS status and error is represented as a `status` JSON object with a well defined structure. Three `long` fields are always present:

 1. `failed` is the number of execution errors that happened, >= 0.
 2. `success` is the number of successful hits, always <= to the initial requested `size` (or `limit()` in this API).
 3. `total` is the total number of results, `total = failed + success`.

Additionally, if `failed > 0`, an `errors` array of size _failed_ is also part of the `status`. It contains strings, one for each index error.

Instead of exposing a sub-object in `SearchQueryResult`, we'll add several top-level methods as described in the table above. Let's detail two of them:

 - `success()`: a `boolean`, true if the search only returned successful hits (no error) or false.
 - `errors()`: a sequence of `String`, of size `errorCount()` (so empty if no errors occurred).

#### The HTTP 400 case
For now when the query is malformed a different response format is used. The API should provide a facade over that and **still return a `SearchQueryResult`**. It will have the following default values:

| Method           | Value in case of `HTTP 400` |
| ---------------- | --------------------------- |
| `count()`        | 1 |
| `rowCount()`     | 0 |
| `errorCount()`   | 1 |
| `errors()`       | a single `string` containing the HTTP 400 body |
| `success()`      | false |
| `took()`         | 0 |
| `totalHits()`    | 0 |
| `maxScore()`     | 0.0 |
| `hits()`         | an empty sequence |
| `facets()`       | an empty map or equivalent "null object" `Facets` |

#### Execution Error Handling
The SDK other querying APIs have usually only exposed the errors as a separate collection of items to retrieve and iterate through. This is fine for SDKs that can return multiple errors, or don't have the concept of an `Exception`.

This also work for other SDKs in which the "single `Exception` thrown in case of error" is idiomatic (eg. Java), but it is a little bit counterintuitive.

The `errors()` method should always be provided in the synchronous API. Additionally, a SDK may expose a `hitsOrFail()` method that will combine `hits()` and `errors()`. Such a method would either return the `hits` or throw an exception **as soon as there is 1 or more `errors`**.

Since multiple exceptions are usually not possible, a custom `SearchQueryExecution` exception will need to be created in order to accumulate several error messages. If an idiomatic composite exception exists in the standard library / dependencies of the SDK, it may be used instead (or extended).

Finally, if the SDK has an **asynchronous API**, the asynchronous processing of `hits()` should be made possible without the need to asynchronously check and combine on the status of the response. To that end, errors would be notified in the same asynchronous avenue than the `hits()`. This can apply to a form of callback, promise or a ReactiveExtension-like observable sequence. Eg in Java this would be the latter, `Observable<SearchQueryRow> hits()`:

```java
Observable<SearchQueryRow> rows = asyncResult.hits(); // <1>

rows.subscribe(
    row -> System.out.println("match in " + row.id()), // <2>
    error -> System.err.println("error during execution: " + error) // <3>
);
```

Assuming an asynchronous version of the result's hits **(1)**, it would be possible in one operation (subscription) to directly process incoming hits **(2)** or get notified of all errors (in a single notification) **(3)**. The composite exception mentioned earlier would apply in this later case.

### 4.2. Hits
Hits are the proper results of the search. They are represented in the JSON response as an array of objects, which we'll call `SearchQueryRow` (to maintain the theme of the "row" found in both view and N1QL queries):

```
SearchQueryRow {
  "index": string
  "id": string
  "score": double
  "explanation": {JSON object}*
  "locations": {JSON object}*
  "fragments": {JSON object}*
  "fields": {JSON object}*
}
```
Each hit is relative to a document and report its `id` and the `index` that was used. A `score` for the hit conveys the relevance of the hit (things like distance from the original term when fuzziness is set can impact the score for example).

Then each hit can have 4 sub-object (`*` indicate they can be omitted in the response):

 - `explanation`: gives detailed explanations on the hit
 - `locations` indicate where the search terms matched inside the document (in terms of offsets)
 - `fragments` are related to highlighting (giving an excerpt of the document where the matching terms are highlighted)
 - `fields` give the complete value of the included fields where matches occurred (if these fields are stored in the index).

The SDK representation of hits is a `SearchQueryRow` class (or equivalent structure):

```java
class SearchQueryRow() {
  String index();
  String id();
  double score();
  //see below for details
  JsonObject explanation();
  HitLocations locations();
  Map<String, String[]> fragments();
  Map<String, String> fields();
}
```

#### Explanations
> **WARNING** This section is only included if the `"explain": true` parameter was used at query time.

This is a large and deeply nested JSON object that should be represented in a generic fashion, idiomatic to the language. For example, if the language includes a generic representation of JSON as a `JsonObject`, then this class should be used.

#### Locations
> **WARNING**: This section is only included if fields are hit for which term vectors are included in the index mapping.

An example of the `locations` *JSON object* is:

```json
"locations": {
        "description": {
          "beer": [
            {
              "pos": 3,
              "start": 11,
              "end": 15,
              "array_positions": null
            },
            {
              "pos": 59,
              "start": 325,
              "end": 329,
              "array_positions": null
            }
          ]
        },
        "name": {
          "beer": [
            {
              "pos": 3,
              "start": 11,
              "end": 15,
              "array_positions": null
            }
          ]
        }
      }
```

As we can see, this is a nested structure:

 1. At top level, JSON objects. The attribute name of each object is the name of the `field` it relates to.
 2. In this JSON object we'll have arrays of hit locations. Each array's attribute name is the term it relates to, as found inside that particular field's index. This is the indexed `term` (as opposed to both the query term and the actual occurrence, called a *token*).
 3. The array of hit locations can contain multiple locations. Each is a JSON object with the following structure:

```
HitLocation {
    "pos": int
    "start": int
    "end": int
    "array_positions": array of long | null
}
```

> **To clarify on `array_positions`:**
> this element is `null` when the field isn't a path that contains arrays.
> On the other end, sometimes the term is found nested inside an array. Note that FTS will flatten such structures, so for example if the term is found in an array "`hobbies`" of an array of "`friends`", the field reported would be `friends.hobbies`.
>
> That alone wouldn't help in locating the term in the document, as it can have multiple friends each with multiple hobbies.
>
> In that case, the `array_positions` would contain two values: one that gives the entry to look for in the first array in the path, `friends`, and one that gives the entry to look for in that friend's `hobbies`. Then pos/start/end all relate to that particular entry, where the term is located. For example: `"array_positions": [ 0, 3 ]` for the first friend's fourth hobby.

The proposed pseudocode counterpart for the whole `locations` section is a `HitLocations` class storing `HitLocation` elements. It would make sense to back it with nested `Map` (or equivalent in the target language, eg. hash, associative array...):

```java
class HitLocation {
    @NotNull String field;
    @NotNull String term;
	@NotNull long pos;
	@NotNull long start;
	@NotNull long end;
	@Nullable long[] arrayPositions;
}

interface HitLocations {
	//add a location and allow method chaining
	HitLocations add(HitLocation l);

	//list all locations for a given field (any term)
	List<HitLocation> get(String field);

	//list all locations for a given field and term
	List<HitLocation> get(String field, String term);

	//list all locations (any field, any term)
	List<HitLocation> getAll();

	//size of all()
	long count();

	//list the fields in this location
	List<String> fields();

	//list the terms for a given field
	List<String> termsFor(String field);

	//list all terms in this locations, considering all fields (so a set)
	Set<String> terms();
}

HitLocations locs = new HitLocations();

locs.add(new HitLocation("description", "beer", 3, 11, 15))
	.add(new HitLocation("description", "beer", 59, 325, 329))
	.add(new HitLocation("name", "beer", 3, 11, 15));
```

> An idiomatic structure can be substituted to the `HitLocations` and `HitLocation` classes, as long as the following operations are possible:
>
>  - easy adding of hit location representation in way it can be grown while parsing the chunks of the response
>  - getting all locations (`getAll()`)
>  - getting locations by field and locations by field+term (`get(field[, term])`)
>  - listing fields (`fields()`)
>  - listing terms for a given field (`termsFor(field)`)
>  - listing all terms (`terms()`)

The use of a class would allow for an empty `HitLocations` to be present when the JSON response doesn't contain this section.

#### Fragments
> **WARNING**: This section is only included if fields are hit that are **stored** in the index, **including term vectors**.

An example of the `fragments` *JSON object* is:

```json
"fragments": {
        "description": [
          "‚Ä¶rsey <mark>Beer</mark> Co. is dedicated to crafting quality <mark>beer</mark> for all; from the occasional <mark>beer</mark> drinker to the <mark>beer</mark> aficionado. We believe that good products come from good people, and strive to do our very bes‚Ä¶"
        ],
        "name": [
          "New Jersey <mark>Beer</mark> Company"
        ]
      }
```

It is made of a single JSON object in which each attribute is a field's name (into which some terms matched). The value of each attribute is an array of excerpts from the document, into which hits are highlighted by being put between `<mark>` tags.

The array can contain multiple entries (eg. if the hits are far apart in the document). **TODO clarify when**.

The proposed pseudocode counterpart for the whole `fragments` section is a multi-value `Map` (or equivalent in the target language, eg. hash, associative array...), each entry containing a `sequence` of `strings` (eg. list, array...):

```java
Map<String, String[]> fragments() { }

String[] field1 = new String[] { "‚Ä¶rsey <mark>Beer</mark> Co" };
String[] field2 = new String[] { "New Jersey <mark>Beer</mark> Company" };

Map fragments = new Map();
fragments.put("description", field1);
fragments.put("name", field2);
```

> An adhoc class or structure can be substituted to this simple representation as long as the following operations are possible:
>
>  - iterate over fields
>  - get all fragments for a given field

#### Fields
> **WARNING**: This section is only included if at least one requested `fields` has term vectors included in its index mapping.

An example of the `fields` *JSON object* is:

```json
"fields": {
        "description": "New Jersey Beer Co. is dedicated to crafting quality beer for all; from the occasional beer drinker to the beer aficionado.",
        "name": "New Jersey Beer Company"
      }
```

The fields section outputs complete values from the fields that were requested at query time. It contains one attribute per requested field, mapping to the string of the complete field's content.

> **NOTE**: For the section to appear, some fields must have been requested in the top level `fields` section of the query and the corresponding fields must be **stored** in the index.

The proposed pseudocode counterpart for the whole `fields` section is a `Map` (or equivalent in the target language, eg. hash, associative array...), each entry being the `field -> string value` association:

```java
Map<String, String> fields() { }

Map fields = new Map();
fields.put("description", "New Jersey Beer Co is dedicated to crafting...");
fields.put("name", "New Jersey Beer Company");
```
> An adhoc class or struct shouldn't be needed for this direct `field -> value` association as most languages will have an equivalent. If that was not the case however, the adhoc class/structure would need to allow the retrieval of a value, given a field's name.


### 4.3. Facet Results
The `facets` part of the result, a sibling to `hits`, contains information relative to the facets the user asked for. If no `facets` section was provided in the query, this section is omitted.

Note that the whole `facets` section **is a single JSON object**. The `name` of each facet, which is defined at query time by the user, is represented in the attribute names.

An individual facet result has both metadata and details, as each facet can define ranges into which results are categorized. The JSON representation of a single facet's results looks like this:

```
FacetResult {
    "field": string
    "total": long
    "missing": long
    "other": long
    "terms": [ {TermRange}, ... ] <1>
    "numeric_ranges": [ {NumericRange}, ...] <1>
    "date_ranges": [ {DateRange}, ... ] <1>
}
```
(1) all mutually exclusive (`terms`, `numeric_ranges` and `date_ranges` cannot be combined).

See the following JSON example:

```
"facets": {
    "category": { <1>
      "field": "style",
          ...
      "terms": [ ... ]
    },
    "strength": { <2>
      "field": "abv",
          ...
      "numeric_ranges": [ ... ]
    },
    "updateRange": { <3>
      "field": "updated",
          ...
      "date_ranges": [ ... ]
    }
  }
```
We omitted part of the section, but this shows that we have 3 facets: a _term_ facet **(1)** named "category", a _numeric_ facet **(2)** named "strength" and a _date_ facet **(3)** named "updateRange".

The section could be represented by a `Map` (or equivalent, eg. associative array).

```java
Map<String, FacetResult> facets();
```

It could also be represented by any other adequate `Facets` class or structure, as long as the following operations are possible:

 - iteration of all the facets
 - retrieval of a facet by name

In code, individual facet results could be represented by an interface and three concrete implementations, one for each facet type:

```java
interface FacetResult {
    String name();
    String field();
    long total();
    long missing();
    long other();
}
```

Note the `name` is made part of the `FacetResult`, so that it can be used in isolation.

#### Term Facet Results
```java
class TermFacetResult implements FacetResult {
	//... all from FacetResult, plus:
	List<TermRange> terms();
}
```

The JSON structure of each **term range** is:

```
TermRange {
	"name": string //the "category" or term
	"count": long //how many times this term was seen
}
```
This can be directly mapped to a `TermRange` class or the appropriate structure in the target language.

When requesting a term facet, the user provides a `size` and a `field`. Each term in this field will be considered as a unique range (a "bucket"), and the `TermFacetResult` will contain the first _size_ terms, ordered by occurrence count. So in a `TermRange`, the `name` is the "category" or term and the `count` is the number of times this term was seen.

#### Numeric Range Facet Results
```java
class NumericFacetResult implements FacetResult {
	//... all from FacetResult, plus:
	List<NumericRange> numericRanges();
}
```

The JSON structure of each **numeric range** is:

```
NumericRange {
    "name": string //the name given to the range in facet query
    "min": long //the minimum value considered in the range (inclusive)
    "max": long //the maximum value considered in the range (inclusive)
    "count": long //how many terms were included in this range?
}
```
This can be directly mapped to a `NumericRange` class or the appropriate structure in the target language.

When requesting a numeric facet, the user defines ranges (also called buckets) and gives them names. All bounds are inclusive, so a term can be categorized into several overlapping buckets.

#### Date Range Facet Results
```java
class DateFacetResult implements FacetResult {
	//... all from FacetResult, plus:
	List<DateRange> dateRanges();
}
```

The JSON structure of each **date range** is:

```
DateRange {
    "name": string //the name given to the range in facet query
    "start": string //the minimum date ("YYYY-MM-DD HH:MM:SS") in range (inclusive)
    "end": string //the maximum date in range (inclusive)
    "count": long //how many terms were included in this range?
}
```
This can be directly mapped to a `DateRange` class or the appropriate structure in the target language.

When requesting a date facet, the user defines ranges (also called buckets) and gives them names. All bounds are inclusive, so a term can be categorized into several overlapping buckets.


# Language Specifics
In this section, the abstract design parts need to be broken down on the SDK level by each maintainer and signed off eventually.

| Generic | NET         | Java   | NodeJS | Go  | C   | PHP | Python | Ruby |
| ------- | ----------- | ------ | ------ | --- | --- | --- | ------ | ---- |


# Unresolved Questions
- Bleve/CBFT supports more options than right now officially documented/specified in this RFC. We need to check if those should be included as well.
- I wonder if its possible that the compound queries can be put into one API?
- the response also returns the request, seems a little wasteful on network bandwith?
	<br/>**=>** this is actually the request that FTS ended up actually executing. Due to optimizations and parsing, it could be different from the one passed in by the user. In such case, exposing it might help users debug the situation (especially if they receive results that they don't expect).

# Signoff
If signed off, each representative agrees both the API and the behavior will be implemented as specified.

| Language | Representative | Date       |
| -------- | -------------- | ---------- |
| Java     | Michael N.     | 01.01.1960 |